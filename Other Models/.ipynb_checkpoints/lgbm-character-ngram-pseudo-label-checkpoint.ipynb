{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I attempted to use pseudo labelling which does the following:\n",
    "1. Train on train set\n",
    "2. Predict values on test set, keep the predicted y values\n",
    "3. Concatenate train and test set with the y from train and predicted y from test set \n",
    "<br><br>\n",
    "My score did not improve, it deproved from 0.815 on the public leaderboard to 0.811 so I decided not to use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Ignore scipy warnings as it was intended to convert to sparse matrix below\n",
    "warnings.filterwarnings(\"ignore\", message=\"Converting data to scipy sparse matrix.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import coo_matrix, hstack, vstack\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import hyperopt\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from lightgbm import LGBMClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../datasets/preprocessed_train.csv\")\n",
    "test = pd.read_csv(\"../datasets/preprocessed_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# We will just lowercase everything, and sub all digits with 1 as per the results of the hyperparameter tuning notebook\n",
    "train[\"Comment\"] = train[\"Comment\"].apply(lambda x: re.sub('\\d', '1', x.lower()))\n",
    "test[\"Comment\"] = test[\"Comment\"].apply(lambda x: re.sub('\\d', '1', x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to split into train and test sets\n",
    "def get_train_test(train, test = None, ngram_range = (1,1), max_features=None, random_state=1, test_size=0.1, min_df=5):\n",
    "    \n",
    "    if type(test) != pd.core.frame.DataFrame:\n",
    "        # Just to check if test is provided, then we'll do train, test instead\n",
    "        # of train val split\n",
    "        X = train.Comment\n",
    "        y = train.Outcome\n",
    "        \n",
    "        # We split by using test_size for y_val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=random_state, test_size=test_size)\n",
    "        \n",
    "        # We're using tfidf vectorizer for our analysis, character level model\n",
    "        tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=ngram_range, max_features=max_features, min_df=min_df)\n",
    "        \n",
    "        print(\"Fitting...\")\n",
    "        start = time.time()\n",
    "        # Fit transform the training, ONLY on training\n",
    "        X_train_dtm =  tfidf_vect_ngram_chars.fit_transform(X_train) \n",
    "        # Transform the x_val\n",
    "        X_val_dtm =  tfidf_vect_ngram_chars.transform(X_val) \n",
    "        print(f\"Operation Took {round(start-time.time(), 2)}s\")\n",
    "        print(X_train_dtm.shape, X_val_dtm.shape)\n",
    "\n",
    "        # Adding in additional variables from EDA\n",
    "        add_var_df = train.loc[X_train.index].reset_index()[['num_numbers', 'prop_numbers', 'num_words',\n",
    "               'num_punctuation', 'prop_punctuation', 'nchar', 'word_density', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'pron_count']]\n",
    "\n",
    "        for column in add_var_df.columns:\n",
    "            var_sparse = add_var_df[column].values[:, None]\n",
    "            X_train_dtm = hstack((X_train_dtm, var_sparse))\n",
    "\n",
    "        add_var_df = train.loc[X_val.index].reset_index()[['num_numbers', 'prop_numbers', 'num_words',\n",
    "               'num_punctuation', 'prop_punctuation', 'nchar', 'word_density', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'pron_count']]\n",
    "        for column in add_var_df.columns:\n",
    "            var_sparse = add_var_df[column].values[:, None]\n",
    "            X_val_dtm = hstack((X_val_dtm, var_sparse))\n",
    "        \n",
    "        print(\"X_train: \", X_train_dtm.shape)\n",
    "        print(\"X_val: \", X_val_dtm.shape)\n",
    "        \n",
    "        return X_train_dtm, X_val_dtm, y_train, y_val\n",
    "    else:\n",
    "        # We're using tfidf vectorizer for our analysis, character level model\n",
    "        tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=ngram_range, max_features=max_features, min_df=min_df)\n",
    "\n",
    "        print(\"Fitting...\")\n",
    "        start = time.time()\n",
    "        # Fit transform the training, ONLY on training\n",
    "        X_train_dtm =  tfidf_vect_ngram_chars.fit_transform(train.Comment)\n",
    "        # Transform the test comment\n",
    "        X_test_dtm =  tfidf_vect_ngram_chars.transform(test.Comment) \n",
    "        print(f\"Operation Took {time.time()-start}s\")\n",
    "        print(X_train_dtm.shape, X_test_dtm.shape)\n",
    "\n",
    "        # Add in additional variables from EDA\n",
    "        add_var_df = train[['num_numbers', 'prop_numbers', 'num_words',\n",
    "               'num_punctuation', 'prop_punctuation', 'nchar', 'word_density', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'pron_count']]\n",
    "\n",
    "        for column in add_var_df.columns:\n",
    "            var_sparse = add_var_df[column].values[:, None]\n",
    "            X_train_dtm = hstack((X_train_dtm, var_sparse))\n",
    "\n",
    "        add_var_df = test[['num_numbers', 'prop_numbers', 'num_words',\n",
    "               'num_punctuation', 'prop_punctuation', 'nchar', 'word_density', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'pron_count']]\n",
    "        for column in add_var_df.columns:\n",
    "            var_sparse = add_var_df[column].values[:, None]\n",
    "            X_test_dtm = hstack((X_test_dtm, var_sparse))\n",
    "        \n",
    "        print(X_train_dtm.shape, X_test_dtm.shape)\n",
    "        \n",
    "        print(\"X_train: \", X_train_dtm.shape)\n",
    "        print(\"X_test: \", X_test_dtm.shape)\n",
    "        \n",
    "        return X_train_dtm, X_test_dtm, train.Outcome\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters from bayesian optimisation\n",
    "lg_params = {'boosting_type': 'gbdt',\n",
    " 'class_weight': 'balanced',\n",
    " 'colsample_bytree': 0.6370495458782991,\n",
    " 'learning_rate': 0.1,\n",
    " 'max_depth': 200,\n",
    " 'metric': 'auc',\n",
    " 'min_child_samples': 20,\n",
    " 'n_estimators': 200,\n",
    " 'num_leaves': 25,\n",
    " 'objective': 'binary',\n",
    " 'random_state': 1234,\n",
    " 'reg_alpha': 0.0720812229772364,\n",
    " 'reg_lambda': 1.87246159415014}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting...\n",
      "Operation Took -138.59s\n",
      "(40013, 441293) (4446, 441293)\n",
      "X_train:  (40013, 441305)\n",
      "X_val:  (4446, 441305)\n",
      "CPU times: user 40min 52s, sys: 12.8 s, total: 41min 5s\n",
      "Wall time: 11min 4s\n",
      "Train\n",
      "Accuracy:  0.8401019668607702\n",
      "Auroc:  0.842641819662503\n",
      "Auroc:  0.9227164749266271\n",
      "Validation\n",
      "Accuracy:  0.7458389563652722\n",
      "Auroc:  0.7463868329048982\n",
      "Auroc:  0.8187717814216781\n",
      "Entire Process Took 838.03seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "X_train, X_val, y_train, y_val = get_train_test(train, test = None, ngram_range = (2,5), \n",
    "                    max_features=None, random_state=1, test_size=0.1)\n",
    "\n",
    "LG = LGBMClassifier(**lg_params)\n",
    "%time LG.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Train\")\n",
    "y_pred_class = LG.predict(X_train)\n",
    "# Comparison between vanilla roc_auc using predict vs if we use predict_proba\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_train, y_pred_class))\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_train, y_pred_class))\n",
    "y_pred_class = LG.predict_proba(X_train)\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_train, y_pred_class[:, 1]))\n",
    "\n",
    "print(\"Validation\")\n",
    "y_pred_class = LG.predict(X_val)\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_val, y_pred_class))\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_val, y_pred_class))\n",
    "y_pred_class = LG.predict_proba(X_val)\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_val, y_pred_class[:, 1]))\n",
    "end = time.time() - start\n",
    "print(f\"Entire Process Took {round(end,2)}seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the train and val here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45min 6s, sys: 8.01 s, total: 45min 14s\n",
      "Wall time: 12min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "               colsample_bytree=0.6370495458782991, importance_type='split',\n",
       "               learning_rate=0.1, max_depth=200, metric='auc',\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=200, n_jobs=-1, num_leaves=25, objective='binary',\n",
       "               random_state=1234, reg_alpha=0.0720812229772364,\n",
       "               reg_lambda=1.87246159415014, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Form new y using the predicted labels from the model\n",
    "new_y = pd.concat([y_train, pd.Series(LG.predict(X_val))])\n",
    "# Merge X_train and X_val\n",
    "new_train = vstack((X_train, X_val))\n",
    "\n",
    "# Predict using the y_train, and the PREDICTED values of X_val\n",
    "LG = LGBMClassifier(**lg_params)\n",
    "%time LG.fit(new_train, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Train\n",
      "Accuracy:  0.7435897435897436\n",
      "Auroc:  0.7446294012695237\n",
      "Auroc:  0.8206329181904359\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"New Train\")\n",
    "# Use the new model to predict just X_val\n",
    "y_pred_class = LG.predict(X_val)\n",
    "# Comparison between vanilla roc_auc using predict vs if we use predict_proba\n",
    "# Compare against actual y_val\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_val, y_pred_class))\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_val, y_pred_class))\n",
    "y_pred_class = LG.predict_proba(X_val)\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_val, y_pred_class[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did better for the train set! But when I tried it on the test set, it didn't work. It seems that we have mixed performance from this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting...\n",
      "Operation Took 238.39069437980652s\n",
      "(44459, 470340) (27924, 470340)\n",
      "(44459, 470352) (27924, 470352)\n",
      "X_train:  (44459, 470352)\n",
      "X_test:  (27924, 470352)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train = get_train_test(train, test = test, ngram_range = (2,5), \n",
    "                    max_features=None, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44min 46s, sys: 6.87 s, total: 44min 53s\n",
      "Wall time: 12min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "               colsample_bytree=0.6370495458782991, importance_type='split',\n",
       "               learning_rate=0.1, max_depth=200, metric='auc',\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=200, n_jobs=-1, num_leaves=25, objective='binary',\n",
       "               random_state=1234, reg_alpha=0.0720812229772364,\n",
       "               reg_lambda=1.87246159415014, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LG = LGBMClassifier(**lg_params)\n",
    "%time LG.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 8min 42s, sys: 14.5 s, total: 1h 8min 56s\n",
      "Wall time: 19min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "               colsample_bytree=0.6370495458782991, importance_type='split',\n",
       "               learning_rate=0.1, max_depth=200, metric='auc',\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=200, n_jobs=-1, num_leaves=25, objective='binary',\n",
       "               random_state=1234, reg_alpha=0.0720812229772364,\n",
       "               reg_lambda=1.87246159415014, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y = pd.concat([y_train, pd.Series(LG.predict(X_test))])\n",
    "new_train = vstack((X_train, X_test))\n",
    "\n",
    "LG = LGBMClassifier(**lg_params)\n",
    "%time LG.fit(new_train, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = LG.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Outcome\"] = y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"Id\", \"Outcome\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
