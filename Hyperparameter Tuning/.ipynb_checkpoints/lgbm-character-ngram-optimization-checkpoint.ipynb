{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import hyperopt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import coo_matrix, hstack, vstack\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Ignore scipy warnings as it was intended to convert to sparse matrix below\n",
    "warnings.filterwarnings(\"ignore\", message=\"Converting data to scipy sparse matrix.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../datasets/preprocessed_train.csv\")\n",
    "test = pd.read_csv(\"../datasets/preprocessed_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Lower and place with digits since this was found to be one of the better combinations\n",
    "train[\"Processed\"] = train[\"Comment\"].apply(lambda x: re.sub('\\d', '1', x.lower()))\n",
    "test[\"Processed\"] = test[\"Comment\"].apply(lambda x: re.sub('\\d', '1', x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get train, val and test data\n",
    "def get_train_test(train, test = None, ngram_range = (1,1), max_features=None, random_state=1, test_size=0.1, min_df=5):\n",
    "    \n",
    "    if type(test) != pd.core.frame.DataFrame:\n",
    "        # To check if we want to split into train val, or train test\n",
    "        \n",
    "        # Use only the train data for train val split\n",
    "        X = train.Processed\n",
    "        y = train.Outcome\n",
    "        \n",
    "        # split into train and test set, using random_state so that it is reproducable\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=random_state, test_size=test_size)\n",
    "        \n",
    "        # We use tfidf character level analyser\n",
    "        tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=ngram_range, max_features=max_features, min_df=min_df)\n",
    "\n",
    "        print(\"Fitting...\")\n",
    "        start = time.time()\n",
    "        # Fit transform only on the train set, use it to transform the val set\n",
    "        X_train_dtm =  tfidf_vect_ngram_chars.fit_transform(X_train) \n",
    "        X_val_dtm =  tfidf_vect_ngram_chars.transform(X_val) \n",
    "        print(f\"Operation Took {round(start-time.time(), 2)}s\")\n",
    "        print(X_train_dtm.shape, X_val_dtm.shape)\n",
    "\n",
    "        # Next, we need to add in the other variables from EDA, need to use scipy to maintain the sparse matrix or we will run out of memory\n",
    "        add_var_df = train.loc[X_train.index].reset_index()[['num_numbers', 'prop_numbers', 'num_words',\n",
    "               'num_punctuation', 'prop_punctuation', 'nchar', 'word_density', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'pron_count']]\n",
    "\n",
    "        for column in add_var_df.columns:\n",
    "            var_sparse = add_var_df[column].values[:, None]\n",
    "            # Stacks horizontally, effectively increasing columns of features to include our EDA\n",
    "            X_train_dtm = hstack((X_train_dtm, var_sparse))\n",
    "\n",
    "        # Repeat the same for the validation set\n",
    "        add_var_df = train.loc[X_val.index].reset_index()[['num_numbers', 'prop_numbers', 'num_words',\n",
    "               'num_punctuation', 'prop_punctuation', 'nchar', 'word_density', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'pron_count']]\n",
    "        for column in add_var_df.columns:\n",
    "            var_sparse = add_var_df[column].values[:, None]\n",
    "            X_val_dtm = hstack((X_val_dtm, var_sparse))\n",
    "        \n",
    "        print(\"X_train: \", X_train_dtm.shape)\n",
    "        print(\"X_val: \", X_val_dtm.shape)\n",
    "        \n",
    "        return X_train_dtm, X_val_dtm, y_train, y_val\n",
    "    else:\n",
    "        # We use tfidf character level analyser\n",
    "        tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=ngram_range, max_features=max_features, min_df=min_df)\n",
    "\n",
    "        print(\"Fitting...\")\n",
    "        start = time.time()\n",
    "        # Fit on train, transform train and test\n",
    "        X_train_dtm =  tfidf_vect_ngram_chars.fit_transform(train.Processed) \n",
    "        X_test_dtm =  tfidf_vect_ngram_chars.transform(test.Processed) \n",
    "        print(f\"Operation Took {time.time()-start}s\")\n",
    "        print(X_train_dtm.shape, X_test_dtm.shape)\n",
    "\n",
    "        # Next, we need to add in the other variables from EDA, need to use scipy to maintain the sparse matrix or we will run out of memory\n",
    "        add_var_df = train[['num_numbers', 'prop_numbers', 'num_words',\n",
    "               'num_punctuation', 'prop_punctuation', 'nchar', 'word_density', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'pron_count']]\n",
    "\n",
    "        for column in add_var_df.columns:\n",
    "            var_sparse = add_var_df[column].values[:, None]\n",
    "            # Stacks horizontally, effectively increasing columns of features to include our EDA\n",
    "            X_train_dtm = hstack((X_train_dtm, var_sparse))\n",
    "\n",
    "        # Repeat the same for the test set\n",
    "        add_var_df = test[['num_numbers', 'prop_numbers', 'num_words',\n",
    "               'num_punctuation', 'prop_punctuation', 'nchar', 'word_density', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'pron_count']]\n",
    "        for column in add_var_df.columns:\n",
    "            var_sparse = add_var_df[column].values[:, None]\n",
    "            X_test_dtm = hstack((X_test_dtm, var_sparse))\n",
    "        \n",
    "        print(X_train_dtm.shape, X_test_dtm.shape)\n",
    "        \n",
    "        print(\"X_train: \", X_train_dtm.shape)\n",
    "        print(\"X_test: \", X_test_dtm.shape)\n",
    "        \n",
    "        return X_train_dtm, X_test_dtm, train.Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting...\n",
      "Operation Took -165.83s\n",
      "(40013, 441293) (4446, 441293)\n",
      "X_train:  (40013, 441305)\n",
      "X_val:  (4446, 441305)\n",
      "CPU times: user 32min 24s, sys: 16.1 s, total: 32min 40s\n",
      "Wall time: 9min 3s\n",
      "Train\n",
      "Accuracy:  0.8101117136930498\n",
      "Auroc:  0.8125293615047017\n",
      "Auroc:  0.8982312929842518\n",
      "Validation\n",
      "Accuracy:  0.7341430499325237\n",
      "Auroc:  0.7357298958648195\n",
      "Auroc:  0.810908915822502\n",
      "Total Time Elapsed: 745.45s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# ngram range set to 2,5 because this was found to yield the best results, default to 50 min df since it helps to reduce the dimensionality of\n",
    "# data while not affecting performance too much\n",
    "X_train, X_val, y_train, y_val = get_train_test(train, test = None, ngram_range = (2,5))\n",
    "\n",
    "LG = LGBMClassifier(class_weight='balanced')\n",
    "%time LG.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Train\")\n",
    "y_pred_class = LG.predict(X_train)\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_train, y_pred_class))\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_train, y_pred_class))\n",
    "y_pred_class = LG.predict_proba(X_train)[:, 1]\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_train, y_pred_class))\n",
    "\n",
    "y_pred_class = LG.predict(X_val)\n",
    "print(\"Validation\")\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_val, y_pred_class))\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_val, y_pred_class))\n",
    "y_pred_class = LG.predict_proba(X_val)[:, 1]\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_val, y_pred_class))\n",
    "print(f\"Total Time Elapsed: {round(time.time() - start, 2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set maximum number of evaluations\n",
    "max_evals = 40\n",
    "\n",
    "# Define spacing to run optimiser on, including regularization that is neccessary due to the nature of the dimentionality of the data\n",
    "lg_space ={'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart', 'goss']),\n",
    "           'num_leaves': hp.choice('num_leaves', [20, 25, 30, 35, 40]),\n",
    "           'max_depth': hp.choice('max_depth', [-1, 50, 100, 150, 200]),\n",
    "           'learning_rate': 0.1,\n",
    "           'n_estimators': hp.choice('n_estimators', [50, 100, 150, 200]),\n",
    "           'objective': 'binary',\n",
    "           'class_weight': 'balanced',\n",
    "           'min_child_samples': hp.choice('min_child_weight', [10, 15, 20, 25, 30]),\n",
    "           'colsample_bytree': hp.uniform ('colsample_bytree', 0.5,0.8),\n",
    "           'reg_alpha': hp.uniform ('reg_alpha', 0,0.1),\n",
    "           'reg_lambda':hp.uniform ('reg_lambda', 1.5,3),\n",
    "           'random_state':1234,\n",
    "           'metric':'auc' # optimise for auc, the metric we're to be measured against\n",
    "#            'device':'gpu',\n",
    "#            'gpu_platform_id':0,\n",
    "#            'gpu_device_id':0\n",
    "          }\n",
    "\n",
    "def lg_objective(space):\n",
    "    model = LGBMClassifier(boosting_type=space['boosting_type'],\n",
    "                          num_leaves=space['num_leaves'],\n",
    "                          max_depth=space['max_depth'],\n",
    "                          learning_rate=space['learning_rate'],\n",
    "                          n_estimators=space['n_estimators'],\n",
    "                          objective=space['objective'],\n",
    "                          class_weight=space['class_weight'],\n",
    "                          min_child_samples=space['min_child_samples'],\n",
    "                          colsample_bytree=space['colsample_bytree'],\n",
    "                          reg_alpha=space['reg_alpha'],\n",
    "                          reg_lambda=space['reg_lambda'],\n",
    "                          random_state=space['random_state'],\n",
    "                          metric=space['metric'])\n",
    "#                           device='gpu', \n",
    "#                           gpu_platform_id=0,\n",
    "#                           gpu_device_id=0) # GPU variables\n",
    "    \n",
    "    auc = cross_val_score(model, X_train, y_train, cv = 2, scoring='roc_auc').mean()\n",
    "\n",
    "    # We aim to maximize accuracy, therefore we return it as a negative value\n",
    "    return {'loss': -auc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [6:37:31<00:00, 596.28s/trial, best loss: -0.8070446587150484]\n"
     ]
    }
   ],
   "source": [
    "# Run optimisations\n",
    "lg_trials = Trials()\n",
    "lg_best = fmin(fn= lg_objective,\n",
    "            space= lg_space,\n",
    "            algo= tpe.suggest,\n",
    "            max_evals = max_evals,\n",
    "            trials= lg_trials,\n",
    "            rstate=np.random.RandomState(1234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': 'balanced',\n",
       " 'colsample_bytree': 0.6370495458782991,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 200,\n",
       " 'metric': 'auc',\n",
       " 'min_child_samples': 20,\n",
       " 'n_estimators': 200,\n",
       " 'num_leaves': 25,\n",
       " 'objective': 'binary',\n",
       " 'random_state': 1234,\n",
       " 'reg_alpha': 0.0720812229772364,\n",
       " 'reg_lambda': 1.87246159415014}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find optimal params\n",
    "lg_params = hyperopt.space_eval(lg_space, lg_best)\n",
    "lg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44min 11s, sys: 8.96 s, total: 44min 20s\n",
      "Wall time: 12min 6s\n",
      "Train\n",
      "Accuracy:  0.8401019668607702\n",
      "Auroc:  0.842641819662503\n",
      "Auroc:  0.9227164749266271\n",
      "Validation\n",
      "Accuracy:  0.7458389563652722\n",
      "Auroc:  0.7463868329048982\n",
      "Auroc:  0.8187717814216781\n",
      "Total Time Elapsed: 750.34s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Use optimal params for prediction\n",
    "LG = LGBMClassifier(**lg_params)\n",
    "%time LG.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Train\")\n",
    "y_pred_class = LG.predict(X_train)\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_train, y_pred_class))\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_train, y_pred_class))\n",
    "y_pred_class = LG.predict_proba(X_train)[:, 1]\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_train, y_pred_class))\n",
    "\n",
    "y_pred_class = LG.predict(X_val)\n",
    "print(\"Validation\")\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_val, y_pred_class))\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_val, y_pred_class))\n",
    "\n",
    "y_pred_class = LG.predict_proba(X_val)[:, 1]\n",
    "print(\"Auroc: \", metrics.roc_auc_score(y_val, y_pred_class))\n",
    "print(f\"Total Time Elapsed: {round(time.time() - start, 2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting...\n",
      "Operation Took 293.12916135787964s\n",
      "(44459, 470340) (27924, 470340)\n",
      "(44459, 470352) (27924, 470352)\n",
      "X_train:  (44459, 470352)\n",
      "X_test:  (27924, 470352)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "X_train, X_test, y_train = get_train_test(train, test = test, ngram_range = (2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47min 30s, sys: 12.5 s, total: 47min 43s\n",
      "Wall time: 13min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "               colsample_bytree=0.6370495458782991, importance_type='split',\n",
       "               learning_rate=0.1, max_depth=200, metric='auc',\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=200, n_jobs=-1, num_leaves=25, objective='binary',\n",
       "               random_state=1234, reg_alpha=0.0720812229772364,\n",
       "               reg_lambda=1.87246159415014, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LG = LGBMClassifier(**lg_params)\n",
    "%time LG.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = LG.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Outcome\"] = y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"Id\", \"Outcome\"]].to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
